{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896aeb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Conv3D, Conv3DTranspose, BatchNormalization, ReLU\n",
    "from tensorflow.python.keras.layers.convolutional import Conv3DTranspose\n",
    "from tensorflow.python.ops.init_ops_v2 import he_normal\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# from tensorflow.keras import mixed_precision\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903baefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scale_img(img):\n",
    "    \"\"\"Convert [0-255] to [-1.0~1.0]\"\"\"\n",
    "    return (np.array(img, dtype=np.float32) / 255.0)*2.0-1.0\n",
    "\n",
    "def _clamp_disp(disp, min_disp, max_disp):\n",
    "    \"\"\"Clip max disparity, ortherwise it'll be hard for network to learn really big disparity/close object\"\"\"\n",
    "    return np.clip(disp, min_disp, max_disp)\n",
    "\n",
    "def StereoDataloader(img_left, img_right, disp_left, img_h, img_w, df_h, df_w, batch_num, ComPerBatch, data_ord, max_disp):\n",
    "    tmp_img = []\n",
    "    tmp_disp = []\n",
    "    if df_h > 32 :\n",
    "        randomH = np.random.randint(0, df_h)\n",
    "    else :\n",
    "        randomH = 0\n",
    "    if df_w > 32 :\n",
    "        randomW = np.random.randint(0, df_w)\n",
    "    else :\n",
    "        randomW = 0\n",
    "        \n",
    "    for idx in range(batch_num*ComPerBatch,(batch_num+1)*ComPerBatch):\n",
    "        l = np.array(Image.open(img_left[data_ord[idx]]))[randomH:randomH+img_h, randomW:randomW+img_w, :]\n",
    "        r = np.array(Image.open(img_right[data_ord[idx]]))[randomH:randomH+img_h, randomW:randomW+img_w, :]\n",
    "        tmp_img.append(np.concatenate((_scale_img(l), _scale_img(r)), axis=2))\n",
    "\n",
    "        dispL = np.loadtxt(disp_left[data_ord[idx]], delimiter=\",\", dtype=np.float32)[randomH:randomH+img_h, randomW:randomW+img_w]\n",
    "        tmp_disp.append(_clamp_disp(dispL,0,max_disp))\n",
    "    \n",
    "    return np.array(tmp_img, dtype=np.float32), np.array(tmp_disp, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bea0428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ConvBR_2D(Layer):\n",
    "    \"\"\"\n",
    "    Conv2D BN ReLU\n",
    "    \"\"\"\n",
    "    def __init__(self, n_feature, kernel_size, strides=(1, 1)):\n",
    "        super(_ConvBR_2D, self).__init__()\n",
    "        self.conv = Conv2D(\n",
    "            n_feature,\n",
    "            kernel_size,\n",
    "            strides,\n",
    "            padding=\"same\",\n",
    "            # kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "        )\n",
    "        self.bn = BatchNormalization()\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, is_training):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x, training=is_training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class _ConvBR_3D(Layer):\n",
    "    \"\"\"\n",
    "    Conv3D BN ReLU\n",
    "    \"\"\"\n",
    "    def __init__(self, n_feature, kernel_size, strides=(1, 1, 1)):\n",
    "        super(_ConvBR_3D, self).__init__()\n",
    "        self.conv = Conv3D(\n",
    "            n_feature,\n",
    "            kernel_size,\n",
    "            strides,\n",
    "            padding=\"same\",\n",
    "            # kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "        )\n",
    "        self.bn = BatchNormalization()\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, is_training):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x, training=is_training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class _DeconvBR_3D(Layer):\n",
    "    \"\"\"\n",
    "    DeConv3D BN ReLU\n",
    "    \"\"\"\n",
    "    def __init__(self, n_feature, kernel_size, strides=(2, 2, 2)):\n",
    "        super(_DeconvBR_3D, self).__init__()\n",
    "        self.conv = Conv3DTranspose(\n",
    "            n_feature,\n",
    "            kernel_size,\n",
    "            strides,\n",
    "            padding=\"same\",\n",
    "            # kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "        )\n",
    "        self.bn = BatchNormalization()\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, is_training):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x, training=is_training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class _GCNetUnary(Layer):\n",
    "    \"\"\"\n",
    "    Unary part (Section 3.1) of GCNet paper\n",
    "    \"\"\"\n",
    "    def __init__(self,feature_n):\n",
    "        super(_GCNetUnary, self).__init__()\n",
    "        self.conv1 = _ConvBR_2D(feature_n, 5, strides=(2, 2))\n",
    "\n",
    "        self.conv_a = list()\n",
    "        self.conv_b = list()\n",
    "        for _ in range(7):\n",
    "            self.conv_a.append(_ConvBR_2D(feature_n, 5))\n",
    "            self.conv_b.append(_ConvBR_2D(feature_n, 5))\n",
    "\n",
    "        self.conv_final = Conv2D(feature_n, 3, padding=\"same\")        \n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, is_training):\n",
    "        x = self.conv1(x, is_training)\n",
    "\n",
    "        for i in range(7):\n",
    "            residual = x\n",
    "            x = self.conv_a[i](x, is_training)\n",
    "            x = self.conv_b[i](x, is_training)\n",
    "            x = x + residual\n",
    "\n",
    "        x = self.conv_final(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db80f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftArgMin(Layer):\n",
    "    def __init__(self, n_disp):\n",
    "        super(SoftArgMin, self).__init__()        \n",
    "        self.disp_indices = tf.range(n_disp, dtype=tf.float32)\n",
    "        self.disp_indices = tf.reshape(self.disp_indices, [1, n_disp, 1, 1])\n",
    "\n",
    "    def call(self, x):\n",
    "        # [N, D, H, W] \n",
    "        x = tf.nn.softmax(x, axis=1)  # compute softmax over all disparity\n",
    "        x = tf.math.multiply(x, self.disp_indices)\n",
    "        # [N, D, H, W] -> [N, H, W]\n",
    "        x = tf.math.reduce_sum(x, axis=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc0442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _GCNetCostVolume(Layer):\n",
    "    \"\"\"\n",
    "    Cost Volume part (Section 3.2) of GCNet paper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_disp):\n",
    "        super(_GCNetCostVolume, self).__init__()\n",
    "        assert n_disp % 2 == 0\n",
    "        self.n_disp = n_disp\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, left, right):   #4차원 matix 생성 관련 부분 확인 필요\n",
    "        # [N, H, W, C]  -> [N, 1, H, W, C]\n",
    "        left = tf.expand_dims(left, axis=1)\n",
    "        right = tf.expand_dims(right, axis=1)\n",
    "        W = right.shape[3]\n",
    "        assert self.n_disp // 2 < W  # Disparity must be lower than W\n",
    "        out = list()\n",
    "        for d in range(self.n_disp // 2):\n",
    "            right_shifted = self._pad_left(right[:, :, :, : W - d, :], d)\n",
    "            left_right_combined = tf.concat([left, right_shifted], axis=4)\n",
    "            out.append(left_right_combined)\n",
    "        # [N, n_disparity, W, H, C]\n",
    "        out = tf.concat(out, axis=1)\n",
    "        return out\n",
    "\n",
    "    def _pad_left(self, x, left_val):\n",
    "        return tf.pad(x, [[0, 0], [0, 0], [0, 0], [left_val, 0], [0, 0]])\n",
    "    \n",
    "\n",
    "class _GCNetRegularization(Layer):\n",
    "    \"\"\"\n",
    "    Regularization part (Section 3.3) of GCNet Paper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_n):\n",
    "        super(_GCNetRegularization, self).__init__()\n",
    "        self.conv1 = _ConvBR_3D(feature_n, 3)\n",
    "        self.conv2 = _ConvBR_3D(feature_n, 3)\n",
    "\n",
    "        self.conv3 = _ConvBR_3D(feature_n*2, 3, strides=(2, 2, 2))\n",
    "        self.conv4 = _ConvBR_3D(feature_n*2, 3)\n",
    "        self.conv5 = _ConvBR_3D(feature_n*2, 3)\n",
    "\n",
    "        self.conv6 = _ConvBR_3D(feature_n*2, 3, strides=(2, 2, 2))\n",
    "        self.conv7 = _ConvBR_3D(feature_n*2, 3)\n",
    "        self.conv8 = _ConvBR_3D(feature_n*2, 3)\n",
    "\n",
    "        self.conv9 = _ConvBR_3D(feature_n*2, 3, strides=(2, 2, 2))\n",
    "        self.conv10 = _ConvBR_3D(feature_n*2, 3)\n",
    "        self.conv11 = _ConvBR_3D(feature_n*2, 3)\n",
    "\n",
    "        self.conv12 = _ConvBR_3D(feature_n*4, 3, strides=(2, 2, 2))\n",
    "        self.conv13 = _ConvBR_3D(feature_n*4, 3)\n",
    "        self.conv14 = _ConvBR_3D(feature_n*4, 3)\n",
    "\n",
    "        self.deconv1 = _DeconvBR_3D(feature_n*2, 3, strides=(2, 2, 2))\n",
    "        self.deconv2 = _DeconvBR_3D(feature_n*2, 3, strides=(2, 2, 2))\n",
    "        self.deconv3 = _DeconvBR_3D(feature_n*2, 3, strides=(2, 2, 2))\n",
    "        self.deconv4 = _DeconvBR_3D(feature_n, 3, strides=(2, 2, 2))\n",
    "        self.deconv_final = Conv3DTranspose(1, 3, strides=(2, 2, 2), padding=\"same\")\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, cost_volume, is_training):\n",
    "        conv1 = self.conv1(cost_volume, is_training)\n",
    "        conv2 = self.conv2(conv1, is_training)\n",
    "\n",
    "        conv3 = self.conv3(cost_volume, is_training)\n",
    "        conv4 = self.conv4(conv3, is_training)\n",
    "        conv5 = self.conv5(conv4, is_training)\n",
    "\n",
    "        conv6 = self.conv6(conv3, is_training)\n",
    "        conv7 = self.conv7(conv6, is_training)\n",
    "        conv8 = self.conv8(conv7, is_training)\n",
    "\n",
    "        conv9 = self.conv9(conv6, is_training)\n",
    "        conv10 = self.conv10(conv9, is_training)\n",
    "        conv11 = self.conv11(conv10, is_training)\n",
    "\n",
    "        conv12 = self.conv12(conv9, is_training)\n",
    "        conv13 = self.conv13(conv12, is_training)\n",
    "        conv14 = self.conv14(conv13, is_training)\n",
    "\n",
    "        deconv1 = self.deconv1(conv14, is_training)\n",
    "        deconv1 = deconv1 + conv11\n",
    "\n",
    "        deconv2 = self.deconv2(deconv1, is_training)\n",
    "        deconv2 = deconv2 + conv8\n",
    "\n",
    "        deconv3 = self.deconv3(deconv2, is_training)\n",
    "        deconv3 = deconv3 + conv5\n",
    "\n",
    "        deconv4 = self.deconv4(deconv3, is_training)\n",
    "        deconv4 = deconv4 + conv2\n",
    "\n",
    "        deconv_final = self.deconv_final(deconv4)        \n",
    "        # [N, D, H, W, 1] -> [N, D, H, W]\n",
    "        return tf.squeeze(deconv_final, axis=-1)\n",
    "       \n",
    "\n",
    "# Function for finding minimum cost value : SoftargMin\n",
    "class GCNet_basic(Model):\n",
    "    \"\"\"\n",
    "    End-to-End Learning of Geometry and Context for Deep Stereo Regression\n",
    "    https://arxiv.org/abs/1703.04309\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_disp, feature_n):\n",
    "        super(GCNet_basic, self).__init__()        \n",
    "        self.unary_block = _GCNetUnary(feature_n)\n",
    "        self.cost_volume_block = _GCNetCostVolume(max_disp)\n",
    "        self.regularization_block = _GCNetRegularization(feature_n)\n",
    "        self.soft_argmin = SoftArgMin(max_disp)        \n",
    "\n",
    "    @tf.function\n",
    "    def call(self, data, training=False):\n",
    "        left, right = tf.split(data, num_or_size_splits=2, axis=3)\n",
    "        left = self.unary_block(left, training)\n",
    "        right = self.unary_block(right, training)\n",
    "        \n",
    "        cost_volume = self.cost_volume_block(left, right)\n",
    "        reg = self.regularization_block(cost_volume, training)\n",
    "        disp = self.soft_argmin(reg)\n",
    "        \n",
    "        return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13eb7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loading dataset path\n",
    "finl = open('gh_imgl.pkl','rb')\n",
    "finr = open('gh_imgr.pkl', 'rb')\n",
    "img_left = pickle.load(finl)\n",
    "img_right = pickle.load(finr)\n",
    "finl.close()\n",
    "finr.close()\n",
    "\n",
    "finl = open('gh_disp.pkl', 'rb')\n",
    "disp_left = pickle.load(finl)\n",
    "finl.close()\n",
    "\n",
    "#training/test data set\n",
    "tot_num1 = len(img_left)//2 # Half number, training data\n",
    "tot_num2 = len(img_left) # total number, training+test data\n",
    "file_max = tot_num2 # if training, file_max = tot_num1. Elif testing performance,file_max = tot_num2. \n",
    "\n",
    "# data size\n",
    "max_w = 984\n",
    "max_h = 560\n",
    "max_disp = 160\n",
    "\n",
    "img_w = 960\n",
    "img_h = 544\n",
    "df_w = max_w - img_w\n",
    "df_h = max_h - img_h\n",
    "\n",
    "feature_n = 32 # Default Feature Number of GC-Net\n",
    "ComPerBatch = 1 #24 #256 # component number per batch\n",
    "batch_size = np.int32(tot_num2/ComPerBatch) # number of batch\n",
    "totpx_batch = img_w*img_h*ComPerBatch\n",
    "\n",
    "# if you want to save data, save_data = 1,\n",
    "#  else save_data = 0\n",
    "save_data = 1\n",
    "\n",
    "# Image save function\n",
    "def disp_img(img, title): \n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='jet')\n",
    "    plt.colorbar(shrink=0.5) \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "\n",
    "vmin = 40\n",
    "vmax = 80\n",
    "vgap = 10\n",
    "# Image save function\n",
    "def _save_img(img, title, dest, file_name, data_ind):\n",
    "#     plt.switch_backend('Agg')\n",
    "    plt.rc('font', size=30)        # 기본 폰트 크기\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(img, cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    cbar.set_ticks(np.arange(vmin, vmax, vgap))  # 32 간격으로 눈금 설정    \n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig('%s/%s_%05d.png' %(dest,file_name,data_ind))\n",
    "    \n",
    "    plt.close()    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b5f99e-e340-4663-b3f9-0d712a7068e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2470/2470"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9632"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IUHM performance #############################################################################\n",
    "max_epochs1 = 52\n",
    "chkdir='saved_model/GCNet_iter%d/' %(max_epochs1)\n",
    "\n",
    "net = GCNet_basic(max_disp, feature_n)\n",
    "net.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss=tf.keras.losses.MeanAbsoluteError(), run_eagerly=True)\n",
    "net.load_weights(chkdir)\n",
    "\n",
    "mix_set = np.arange(file_max) #if training : mix_set = np.random.permutation(file_max)\n",
    "\n",
    "dest_dir='GCNet_iter%d' %(max_epochs1)\n",
    "\n",
    "if not os.path.isdir(dest_dir):\n",
    "    os.makedirs(dest_dir)\n",
    "\n",
    "file_name = '%s/test.csv' %(dest_dir)\n",
    "f = open(file_name, 'w')    \n",
    "f.write('Data No./Number as Disparity Difference, GCNet_GH2470_epc%d loss, ratio of px<=1, <=2, <=3\\n' %(max_epochs1))\n",
    "f.close()\n",
    "\n",
    "for batch_n in range(batch_size):\n",
    "    DB_imgs,DB_disp = StereoDataloader(\n",
    "        img_left = img_left,\n",
    "        img_right = img_right,\n",
    "        disp_left = disp_left,                \n",
    "        img_h = img_h,\n",
    "        img_w = img_w,\n",
    "        df_h = df_h,\n",
    "        df_w = df_w,\n",
    "        batch_num = batch_n, # order of batch\n",
    "        ComPerBatch = ComPerBatch, # component number of a batch\n",
    "        data_ord = mix_set,\n",
    "        max_disp = max_disp\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    if save_data == 0:\n",
    "        print('Batch %d/%d' %(batch_n+1,batch_size))\n",
    "        result = net.predict(DB_imgs, batch_size=1, verbose=1)\n",
    "        result = _clamp_disp(result,0, max_disp)\n",
    "    elif save_data == 1:\n",
    "        print('\\rBatch %d/%d' %(batch_n+1,batch_size), end='')\n",
    "        result = _clamp_disp(net.predict(DB_imgs, batch_size=1, verbose=0),0, max_disp)\n",
    "        loss1 = np.mean(np.abs(DB_disp-result))\n",
    "\n",
    "        file_name = '%s/test.csv' %(dest_dir)\n",
    "        f = open(file_name, 'a')\n",
    "\n",
    "        disp_diff1 = np.abs(DB_disp-result)\n",
    "\n",
    "        f.write('%d, ' %(batch_n+1))\n",
    "\n",
    "        # Model disparity error and px area ratio (<= 1px,2px,3px)        \n",
    "        f.write('%.5f, ' %loss1)        \n",
    "        f.write('%.5f, ' %(np.sum(disp_diff1<=1)/totpx_batch))        \n",
    "        f.write('%.5f, ' %(np.sum(disp_diff1<=2)/totpx_batch))        \n",
    "        f.write('%.5f \\n'%(np.sum(disp_diff1<=3)/totpx_batch))\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        #### Disparity calculated by Trueth Data            \n",
    "        title = 'Ground Truth_Data#%d' %(batch_n+1)\n",
    "        file_name = 'True_Disp'\n",
    "        _save_img(DB_disp[0,:,:], title, dest_dir, file_name, batch_n+1)\n",
    "\n",
    "        #### Disparity calculated by Stereo Camera Data with Model\n",
    "        title = 'GCNet_Data#%d' %(batch_n+1)\n",
    "        file_name = 'Stereo_Disp'\n",
    "        _save_img(result[0,:,:], title, dest_dir, file_name, batch_n+1)\n",
    "\n",
    "        del file_name\n",
    "        del loss1\n",
    "        del disp_diff1\n",
    "        gc.collect()\n",
    "\n",
    "    del DB_imgs\n",
    "    del DB_disp\n",
    "    del result\n",
    "    gc.collect()\n",
    "    \n",
    "del net\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
