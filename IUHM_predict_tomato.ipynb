{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896aeb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.python.keras.layers.convolutional import Conv3DTranspose\n",
    "from tensorflow.python.ops.init_ops_v2 import he_normal\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# from tensorflow.keras import mixed_precision\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903baefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clamp_disp(disp, min_disp, max_disp):\n",
    "    \"\"\"Clip max disparity, ortherwise it'll be hard for network to learn really big disparity/close object\"\"\"\n",
    "    return np.clip(disp, min_disp, max_disp)\n",
    "\n",
    "def histogram_equalization(image):\n",
    "    # 이미지를 float32 타입으로 변환합니다.\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    # 이미지를 [0, 1] 범위로 정규화합니다.\n",
    "    image = tf.clip_by_value(image/255.0, 0.0, 1.0)\n",
    "    \n",
    "    # 이미지의 히스토그램을 계산합니다.\n",
    "    hist = tf.histogram_fixed_width(image, [0.0, 1.0], nbins=256)\n",
    "    \n",
    "    # 누적 분포 함수(Cumulative Distribution Function)를 계산합니다.\n",
    "    cdf = tf.cumsum(hist)\n",
    "    cdf_min = cdf[tf.reduce_min(tf.where(tf.greater(cdf, 0)))]\n",
    "    num_pixels = tf.reduce_sum(hist)\n",
    "    cdf_normalized = (cdf - cdf_min) / (num_pixels - cdf_min)\n",
    "    \n",
    "    # 새로운 이미지를 만듭니다.\n",
    "    image = tf.cast(tf.gather(cdf_normalized, tf.cast(image * 255, tf.int32)), tf.float32)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def StereoDataloader(img_left, img_right, disp_left, img_h, img_w, df_h, df_w, batch_num, ComPerBatch, data_ord, max_disp):\n",
    "    tmp_img = []\n",
    "    tmp_disp = []\n",
    "    if df_h > 32 :\n",
    "        randomH = np.random.randint(0, df_h)\n",
    "    else :\n",
    "        randomH = 0\n",
    "    if df_w > 32 :\n",
    "        randomW = np.random.randint(0, df_w)\n",
    "    else :\n",
    "        randomW = 0\n",
    "    \n",
    "    \n",
    "    for idx in range(batch_num*ComPerBatch,(batch_num+1)*ComPerBatch):\n",
    "        l = np.array(Image.open(img_left[data_ord[idx]]).convert(\"L\"))[randomH:randomH+img_h, randomW:randomW+img_w]\n",
    "        l = np.expand_dims(histogram_equalization(l), axis=2)        \n",
    "        \n",
    "        r = np.array(Image.open(img_right[data_ord[idx]]).convert(\"L\"))[randomH:randomH+img_h, randomW:randomW+img_w]\n",
    "        r = np.expand_dims(histogram_equalization(r), axis=2)        \n",
    "        tmp_img.append(np.concatenate((l,r), axis=2))\n",
    "        \n",
    "        dispL = np.loadtxt(disp_left[data_ord[idx]], delimiter=\",\", dtype=np.float32)[randomH:randomH+img_h, randomW:randomW+img_w]\n",
    "        tmp_disp.append(_clamp_disp(dispL,0,max_disp))\n",
    "    \n",
    "    return np.array(tmp_img, dtype=np.float32), np.array(tmp_disp, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13eb7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loading dataset path\n",
    "k_h = 4\n",
    "k_w = 6\n",
    "\n",
    "finl = open('gh_imgl.pkl','rb')\n",
    "finr = open('gh_imgr.pkl', 'rb')\n",
    "img_left = pickle.load(finl)\n",
    "img_right = pickle.load(finr)\n",
    "finl.close()\n",
    "finr.close()\n",
    "\n",
    "finl = open('gh_disp.pkl', 'rb')\n",
    "disp_left = pickle.load(finl)\n",
    "finl.close()\n",
    "\n",
    "#training/test data set\n",
    "tot_num1 = len(img_left)//2 # Half number, training data\n",
    "tot_num2 = len(img_left) # total number, training+test data\n",
    "file_max = tot_num2 # if training, file_max = tot_num1. Elif testing performance,file_max = tot_num2. \n",
    "\n",
    "# data size\n",
    "max_w = 984\n",
    "max_h = 560\n",
    "max_disp = 160\n",
    "\n",
    "img_w = 960\n",
    "img_h = 544\n",
    "df_w = max_w - img_w\n",
    "df_h = max_h - img_h\n",
    "\n",
    "feature_n = 32 # Default Feature Number of GC-Net\n",
    "ComPerBatch = 1 #24 #256 # component number per batch\n",
    "batch_size = np.int32(tot_num2/ComPerBatch) # number of batch\n",
    "totpx_batch = img_w*img_h*ComPerBatch\n",
    "\n",
    "# if you want to save data, save_data = 1,\n",
    "#  else save_data = 0\n",
    "save_data = 1 \n",
    "\n",
    "# Image save function\n",
    "def disp_img(img, title): \n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='jet')\n",
    "    plt.colorbar(shrink=0.5) \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "\n",
    "vmin = 40\n",
    "vmax = 80\n",
    "vgap = 10\n",
    "# Image save function\n",
    "def _save_img(img, title, dest, file_name, data_ind):\n",
    "#     plt.switch_backend('Agg')\n",
    "    plt.rc('font', size=30)        # 기본 폰트 크기\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(img, cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    cbar.set_ticks(np.arange(vmin, vmax, vgap))  # 32 간격으로 눈금 설정    \n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig('%s/%s_%05d.png' %(dest,file_name,data_ind))\n",
    "    \n",
    "    plt.close()    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b5f99e-e340-4663-b3f9-0d712a7068e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2470/2470"
     ]
    },
    {
     "data": {
      "text/plain": [
       "121252"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IUHM performance #############################################################################\n",
    "max_epochs1 = 177\n",
    "\n",
    "net = tf.keras.models.load_model('saved_model/IUHM_H%dWW%d_iter%d' %(k_h,k_w,max_epochs1))\n",
    "dest_dir='IUHM_H%dWW%d_iter%d' %(k_h,k_w,max_epochs1)\n",
    "\n",
    "if not os.path.isdir(dest_dir):\n",
    "    os.makedirs(dest_dir)\n",
    "\n",
    "mix_set = np.arange(file_max) #if training : mix_set = np.random.permutation(file_max)\n",
    "\n",
    "file_name = '%s/test.csv' %(dest_dir)\n",
    "f = open(file_name, 'w')    \n",
    "f.write('Data No./Number as Disparity Difference, IUHM_H%dW%d_GH2470_epc%d loss, ratio of px<=1, <=2, <=3\\n' %(k_h,k_w,max_epochs1))\n",
    "f.close()\n",
    "\n",
    "for batch_n in range(batch_size):\n",
    "    DB_imgs,DB_disp = StereoDataloader(\n",
    "        img_left = img_left,\n",
    "        img_right = img_right,\n",
    "        disp_left = disp_left,                \n",
    "        img_h = img_h,\n",
    "        img_w = img_w,\n",
    "        df_h = df_h,\n",
    "        df_w = df_w,\n",
    "        batch_num = batch_n, # order of batch\n",
    "        ComPerBatch = ComPerBatch, # component number of a batch\n",
    "        data_ord = mix_set,\n",
    "        max_disp = max_disp\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    if save_data == 0:\n",
    "        print('Batch %d/%d' %(batch_n+1,batch_size))\n",
    "        result = net.predict(DB_imgs, batch_size=1, verbose=1)\n",
    "        result = _clamp_disp(result,0, max_disp)\n",
    "    elif save_data == 1:\n",
    "        print('\\rBatch %d/%d' %(batch_n+1,batch_size), end='')\n",
    "        result = _clamp_disp(net.predict(DB_imgs, batch_size=1, verbose=0),0, max_disp)\n",
    "        loss1 = np.mean(np.abs(DB_disp-result))\n",
    "\n",
    "        file_name = '%s/test.csv' %(dest_dir)\n",
    "        f = open(file_name, 'a')\n",
    "\n",
    "        disp_diff1 = np.abs(DB_disp-result)\n",
    "\n",
    "        f.write('%d, ' %(batch_n+1))\n",
    "\n",
    "        # Model disparity error and px area ratio (<= 1px,2px,3px)        \n",
    "        f.write('%.5f, ' %loss1)        \n",
    "        f.write('%.5f, ' %(np.sum(disp_diff1<=1)/totpx_batch))        \n",
    "        f.write('%.5f, ' %(np.sum(disp_diff1<=2)/totpx_batch))        \n",
    "        f.write('%.5f \\n'%(np.sum(disp_diff1<=3)/totpx_batch))\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        #### Disparity calculated by Trueth Data            \n",
    "        title = 'Ground Truth_Data#%d' %(batch_n+1)\n",
    "        file_name = 'True_Disp'\n",
    "        _save_img(DB_disp[0,:,:], title, dest_dir, file_name, batch_n+1)\n",
    "\n",
    "        #### Disparity calculated by Stereo Camera Data with Model\n",
    "        title = 'IUHM_H%dW%d_Data#%d' %(k_h,k_w,batch_n+1)\n",
    "        file_name = 'Stereo_Disp'\n",
    "        _save_img(result[0,:,:], title, dest_dir, file_name, batch_n+1)\n",
    "\n",
    "        del file_name\n",
    "        del loss1\n",
    "        del disp_diff1\n",
    "        gc.collect()\n",
    "\n",
    "    del DB_imgs\n",
    "    del DB_disp\n",
    "    del result\n",
    "    gc.collect()\n",
    "    \n",
    "del net\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
